{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30c70f-33bb-46b8-98d4-5f1cce96eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Students:\n",
    "## Tamim Dostyar\n",
    "## Brook Peterson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facffb77",
   "metadata": {},
   "source": [
    "# Activity Classification - KNeighborsClassifier Training\n",
    "\n",
    "This notebook trains a KNeighborsClassifier on the physical activity dataset using GridSearchCV for hyperparameter tuning.\n",
    "\n",
    "## Load Data and Prepare Training Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff38d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import importlib\n",
    "\n",
    "import activity_functions\n",
    "importlib.reload(activity_functions)\n",
    "from activity_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c3a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from Kaggle: /home/thuy/.cache/kagglehub/datasets/diegosilvadefrana/fisical-activity-dataset/versions/4/dataset2.csv\n"
     ]
    }
   ],
   "source": [
    "activtity = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e9353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2291244, 33)\n",
      "(572812, 33)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = create_train_test(activtity, test_ratio=0.2)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d5a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_for_train(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ac9f0",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25ba622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def grid_searchCV(X, y):\n",
    "    model = KNeighborsClassifier()\n",
    "    param = {\n",
    "        \"n_neighbors\": [5, 6, 7],\n",
    "        \"p\": [1, 2],\n",
    "        \"weights\": [\"uniform\"],\n",
    "        \"metric\": [\"minkowski\"]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        model,\n",
    "        param,\n",
    "        verbose=1,\n",
    "        refit=True,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    grid.fit(X, y)\n",
    "    return grid\n",
    "\n",
    "best_model = grid_searchCV(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a31e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 5, 'p':...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996677</td>\n",
       "      <td>0.992771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 6, 'p':...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995809</td>\n",
       "      <td>0.991856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 7, 'p':...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994627</td>\n",
       "      <td>0.990363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 5, 'p':...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 6, 'p':...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 7, 'p':...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  rank_test_score  \\\n",
       "1  {'metric': 'minkowski', 'n_neighbors': 5, 'p':...                1   \n",
       "3  {'metric': 'minkowski', 'n_neighbors': 6, 'p':...                2   \n",
       "5  {'metric': 'minkowski', 'n_neighbors': 7, 'p':...                3   \n",
       "0  {'metric': 'minkowski', 'n_neighbors': 5, 'p':...                4   \n",
       "2  {'metric': 'minkowski', 'n_neighbors': 6, 'p':...                4   \n",
       "4  {'metric': 'minkowski', 'n_neighbors': 7, 'p':...                4   \n",
       "\n",
       "   mean_train_score  mean_test_score  \n",
       "1          0.996677         0.992771  \n",
       "3          0.995809         0.991856  \n",
       "5          0.994627         0.990363  \n",
       "0               NaN              NaN  \n",
       "2               NaN              NaN  \n",
       "4               NaN              NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cv_result = pd.DataFrame(best_model.cv_results_)\n",
    "columns = ['params', 'rank_test_score', 'mean_train_score', 'mean_test_score']\n",
    "cv_result = cv_result[columns]\n",
    "cv_result.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbb4f6",
   "metadata": {},
   "source": [
    "## Best Hyperparameters Found\n",
    "\n",
    "Display the best hyperparameters found by GridSearchCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1bd495c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "Best Cross-Validation Accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\")\n",
    "print(best_model.best_params_)\n",
    "print(f\"\\nBest Cross-Validation Accuracy: {best_model.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f4c0a",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the best model on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "874e1abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9962\n",
      "F1-Score:  0.9963\n",
      "Recall:    0.9964\n",
      "Precision: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.996213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_Score    Recall  Precision\n",
       "0  0.996173  0.996299  0.996388   0.996213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "\n",
    "# Predict on test set\n",
    "y_test_hat = best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "compute_scores(y_test, y_test_hat, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba59f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "      Nordic walking       1.00      1.00      1.00     37621\n",
      "    ascending stairs       0.99      0.99      0.99     23443\n",
      "             cycling       1.00      1.00      1.00     32920\n",
      "   descending stairs       0.99      0.98      0.99     20989\n",
      "             ironing       1.00      1.00      1.00     47738\n",
      "               lying       1.00      1.00      1.00     38505\n",
      "        rope jumping       1.00      1.00      1.00      8594\n",
      "             running       1.00      1.00      1.00     19640\n",
      "             sitting       1.00      1.00      1.00     37038\n",
      "            standing       1.00      1.00      1.00     37986\n",
      "transient activities       1.00      0.99      0.99    185515\n",
      "     vacuum cleaning       1.00      1.00      1.00     35071\n",
      "             walking       0.99      1.00      0.99     47752\n",
      "\n",
      "            accuracy                           1.00    572812\n",
      "           macro avg       1.00      1.00      1.00    572812\n",
      "        weighted avg       1.00      1.00      1.00    572812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a9127",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The KNeighborsClassifier was tuned using GridSearchCV with the following hyperparameter grid:\n",
    "- **n_neighbors**: [5, 6, 7]\n",
    "- **weights**: [\"uniform\"]\n",
    "- **metric**: [\"minkowski\"]\n",
    "\n",
    "This resulted in **6 candidate models** evaluated with **3-fold cross-validation** (18 total fits).\n",
    "\n",
    "The best model was selected based on accuracy and evaluated on the held-out test set above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f22c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
