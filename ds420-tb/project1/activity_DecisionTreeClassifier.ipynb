{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d66f29ff",
      "metadata": {
        "id": "d66f29ff"
      },
      "source": [
        "# Activity Classification - DecisionTreeClassifier Training\n",
        "\n",
        "This notebook trains a DecisionTreeClassifier on the physical activity dataset using GridSearchCV for hyperparameter tuning.\n",
        "\n",
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3f3d863f",
      "metadata": {
        "id": "3f3d863f"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c67336",
      "metadata": {},
      "source": [
        "## Load Data and Prepare Training Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9509dc5",
      "metadata": {
        "id": "d9509dc5"
      },
      "outputs": [],
      "source": [
        "%reset -f\n",
        "\n",
        "import importlib\n",
        "\n",
        "import activity_functions\n",
        "importlib.reload(activity_functions)\n",
        "from activity_functions import *\n",
        "\n",
        "\n",
        "# this only works for google colab\n",
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/ds420Projects/project1')\n",
        "# from activity_functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bc5dd216",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc5dd216",
        "outputId": "8b1b4732-c359-417b-d548-b8db410c7065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/diegosilvadefrana/fisical-activity-dataset?dataset_version_number=4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 297M/297M [00:01<00:00, 165MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded from Kaggle: /root/.cache/kagglehub/datasets/diegosilvadefrana/fisical-activity-dataset/versions/4/dataset2.csv\n"
          ]
        }
      ],
      "source": [
        "activtity = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67f728e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67f728e3",
        "outputId": "c0efb420-37ab-4244-dfb1-5ca525b7149b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2291244, 33)\n",
            "(572812, 33)\n"
          ]
        }
      ],
      "source": [
        "df_train, df_test = create_train_test(activtity, test_ratio=0.2)\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "95ccf126",
      "metadata": {
        "id": "95ccf126"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test = prepare_for_train(df_train, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "C6Uj2g-fKsz0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Uj2g-fKsz0",
        "outputId": "1b83ecd8-f123-462d-842d-7c94f6d6bf08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf152f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecf152f7",
        "outputId": "42c35616-a0ad-49ef-da2b-f97220e8700c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def grid_searchCV(X, y):\n",
        "    model = DecisionTreeClassifier(\n",
        "        random_state=42\n",
        "    )\n",
        "    param = {\n",
        "        \"max_depth\": [3, 5, 7, 10],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4],\n",
        "        \"criterion\": [\"gini\", \"entropy\"]\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        model,\n",
        "        param,\n",
        "        verbose=1,\n",
        "        refit=True,\n",
        "        cv=3,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    grid.fit(X, y)\n",
        "    return grid\n",
        "best_model = grid_searchCV(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf398493",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning with GridSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec4e7f4",
      "metadata": {},
      "source": [
        "## Best Hyperparameters Found\n",
        "\n",
        "Display the best hyperparameters found by GridSearchCV:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e36106dd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters:\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'best_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Cross-Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Best Hyperparameters:\")\n",
        "print(best_model.best_params_)\n",
        "print(f\"\\nBest Cross-Validation Accuracy: {best_model.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90464538",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Evaluate the best model on the test set:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eaeff86",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
        "\n",
        "# Predict on test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DecisionTreeClassifier - Test Set Performance\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"F1 Score:  {test_f1:.4f}\")\n",
        "print(f\"Recall:    {test_recall:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a813b102",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9efc1ac",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The DecisionTreeClassifier was tuned using GridSearchCV with the following hyperparameter grid:\n",
        "- **max_depth**: [3, 5, 7, 10]\n",
        "- **min_samples_split**: [2, 5, 10]\n",
        "- **min_samples_leaf**: [1, 2, 4]\n",
        "- **criterion**: [\"gini\", \"entropy\"]\n",
        "\n",
        "This resulted in **72 candidate models** evaluated with **3-fold cross-validation** (216 total fits).\n",
        "\n",
        "The best model was selected based on accuracy and evaluated on the held-out test set above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ee7f9b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DS420",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
